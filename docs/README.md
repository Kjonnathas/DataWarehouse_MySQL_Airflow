![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Postgres](https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white)
![MySQL](https://img.shields.io/badge/mysql-4479A1.svg?style=for-the-badge&logo=mysql&logoColor=white)
![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)

# 1. Descri√ß√£o do Projeto üìã

Este projeto foi desenvolvido com o objetivo de criar uma estrutura robusta de Data Warehouse, abrangendo desde a implementa√ß√£o da modelagem conceitual, l√≥gica e f√≠sica. O trabalho incluiu a cria√ß√£o de um banco de dados transacional (OLTP) e a implementa√ß√£o de um pipeline ETL (Extra√ß√£o, Transforma√ß√£o e Carregamento) para integrar os dados ao Data Warehouse (DW).

O fluxo de dados foi estruturado da seguinte forma:

1. Banco de Dados Transacional (OLTP): Armazenamento inicial dos dados em uma estrutura otimizada para transa√ß√µes.

2. Staging Area: Um ambiente intermedi√°rio para a integra√ß√£o e pr√©-processamento dos dados extra√≠dos.

3. Data Warehouse: Reposit√≥rio final onde os dados transformados s√£o organizados para an√°lises.

Este projeto demonstra o processo completo de desenvolvimento de um Data Warehouse, desde a modelagem inicial at√© a automa√ß√£o de pipelines ETL, proporcionando uma base s√≥lida para an√°lises de dados e suporte √† tomada de decis√µes.

# 2. Objetivo do Projeto üéØ

Desenvolver uma solu√ß√£o completa de Data Warehouse que integre modelagem de dados, cria√ß√£o de um banco transacional (OLTP) e automa√ß√£o de pipelines ETL, utilizando tecnologias modernas como Docker, Airbyte e Apache Airflow. O projeto visa demonstrar, na pr√°tica, o fluxo completo de dados desde a origem at√© a consolida√ß√£o em um ambiente otimizado para an√°lises estrat√©gicas, com foco em escalabilidade, portabilidade e organiza√ß√£o eficiente dos dados. Al√©m disso, busca aplicar os conhecimentos adquiridos na forma√ß√£o de Engenheiro de Dados da Data Science Academy, servindo como inspira√ß√£o para que outros profissionais possam utilizar esta arquitetura em seus pr√≥prios projetos, tanto pessoais quanto profissionais.

# 3. Arquitetura do Projeto üèóÔ∏è

![Arquitetura do Projeto Data Warehouse](/assets/images/arquitetura_projeto.png)

# 4. Modelagem de Dados üèõÔ∏è

## 4.1 Modelo Conceitual (Diagrama Entidade-Relacionamento - DER)

![Modelo Conceitual](/assets/images/modelo_conceitual.png)

## 4.2 Modelo L√≥gico

![Modelo L√≥gico](/assets/images/modelo_logico.png)

## 4.3 Modelo Dimensional

![Modelo Dimensional](/assets/images/modelo_dimensional.png)

# 5. Tecnologias Utilizadas üíª

- Git
- SQL
- PostgreSQL
- MySQL
- Python
- Airbyte
- Apache Airflow
- Docker
- UML

# 6. Descri√ß√£o de como as Tecnologias foram utilizadas atrav√©s da √≥tica da Arquitetura üìù

1.  Cria√ß√£o do Banco de Dados Transacional (OLTP) üè¶

    - Foram gerados diversos arquivos CSV contendo os dados de entrada.
    - Um script Python foi desenvolvido para realizar o carregamento autom√°tico desses arquivos no MySQL, configurado como o banco de dados transacional (OLTP).
    - O banco OLTP foi implementado em um servidor dedicado, executado dentro de um cont√™iner Docker, e consistia em cerca de 30 tabelas criadas previamente atrav√©s de scripts SQL executados diretamente no cliente do MySQL.

2.  Staging Area üõ†Ô∏è

    - Para a staging area, foi configurado outro servidor com PostgreSQL, tamb√©m rodando em um cont√™iner Docker independente.
    - A ferramenta Airbyte foi utilizada para estabelecer a conex√£o entre o banco OLTP (MySQL) e a staging area (PostgreSQL). Essa etapa foi respons√°vel pela extra√ß√£o e carga inicial dos dados, garantindo a separa√ß√£o l√≥gica entre os ambientes.

3.  Transforma√ß√£o e Carga no Data Warehouse (DW) üìä

    - O Apache Airflow foi configurado para orquestrar o pipeline de ETL, utilizando uma DAG personalizada que:

      - Extrai os dados da staging area no PostgreSQL.

      - Transforma os dados aplicando as regras de neg√≥cio necess√°rias.
      - Carrega os dados no Data Warehouse, que tamb√©m foi implementado em PostgreSQL, mas em um servidor e cont√™iner Docker dedicados.

    - As tabelas do DW foram previamente criadas atrav√©s de scripts SQL no cliente do PostgreSQL, garantindo que a estrutura estivesse alinhada ao modelo de dados definido para o projeto.

4.  Automatiza√ß√£o e Integra√ß√£o üîÑ

    - Todo o processo de ETL foi automatizado, permitindo a execu√ß√£o cont√≠nua e eficiente do fluxo de dados entre os diferentes ambientes.

Este projeto n√£o apenas simula uma arquitetura real de Data Warehouse como tamb√©m aplica conceitos fundamentais de engenharia de dados e automa√ß√£o de pipelines. üêçüêò‚öôÔ∏è

# 7. Descri√ß√£o de como as Tecnologias foram utilizadas atrav√©s da √≥tica das Ferramentas üìù

1. <strong> üêç Python </strong>

   O Python foi utilizado para desenvolver scripts que automatizam o carregamento dos dados no MySQL, que funcionou como banco de dados transacional (OLTP) com cerca de 30 tabelas. Os arquivos CSV gerados foram processados e carregados via scripts Python, que atuaram como a ponte entre os dados e o banco de dados, garantindo que as informa√ß√µes fossem corretamente inseridas nas tabelas do MySQL. Al√©m disso, o Python tamb√©m foi utilizado para criar a DAG (Directed Acyclic Graph) no Apache Airflow, orquestrando o fluxo de trabalho do processo de ETL.

2. <strong> üê≥ Docker Desktop </strong>

   O Docker Desktop foi utilizado para criar cont√™ineres isolados e garantir que cada servi√ßo funcionasse em um ambiente controlado e separado. Criei um cont√™iner com o MySQL, que foi respons√°vel pelo banco de dados transacional (OLTP), e um cont√™iner separado com o PostgreSQL para simular a staging area. Al√©m disso, o PostgreSQL foi utilizado no Data Warehouse (DW), que tamb√©m foi configurado dentro de um cont√™iner Docker em um servidor separado. O uso de cont√™ineres facilitou a gest√£o dos servi√ßos e a escalabilidade do projeto.

3. <strong> ü™º Airbyte </strong>

   O Airbyte foi utilizado como ferramenta de integra√ß√£o de dados, conectando a fonte de dados (MySQL) √† staging area (PostgreSQL). Ele foi respons√°vel por extrair os dados do banco de dados MySQL e transferi-los para o PostgreSQL, garantindo que os dados estivessem prontos para serem processados e transformados no fluxo de ETL. O Airbyte automatizou esse processo de movimenta√ß√£o de dados, garantindo a consist√™ncia e a atualiza√ß√£o das informa√ß√µes.

4. <strong> ‚òÅÔ∏è Apache Airflow </strong>

   O Apache Airflow foi a plataforma escolhida para orquestrar todo o processo de ETL. Criei uma DAG (Directed Acyclic Graph) no Airflow para automatizar o fluxo de trabalho. A DAG buscava os dados da staging area no PostgreSQL, aplicava as transforma√ß√µes necess√°rias e, em seguida, carregava os dados transformados no Data Warehouse (DW), que tamb√©m estava hospedado no PostgreSQL. O Airflow garantiu que as etapas do processo de transforma√ß√£o e carregamento dos dados fossem executadas de forma sequencial e programada.

5. <strong> üê¨ MySQL </strong>

   O MySQL foi utilizado como o banco de dados transacional (OLTP) respons√°vel pelo armazenamento das tabelas operacionais com cerca de 30 tabelas. O MySQL recebeu os dados de entrada, que foram carregados por meio de scripts Python. Esse banco de dados foi fundamental para o armazenamento e gerenciamento dos dados brutos, que depois seriam processados e transformados para an√°lises posteriores.

6. <strong> üêò PostgreSQL </strong>

   O PostgreSQL foi utilizado de duas maneiras: como a staging area e como o banco de dados do Data Warehouse (DW). Na staging area, o PostgreSQL recebeu os dados extra√≠dos do MySQL via Airbyte, e no Data Warehouse, o PostgreSQL foi utilizado para armazenar os dados transformados, permitindo consultas anal√≠ticas e a gera√ß√£o de insights de forma eficiente. Antes do processo de ETL come√ßar, as tabelas foram criadas no PostgreSQL com scripts SQL, que definiram a estrutura do banco de dados.

# 8. Exibi√ß√£o do Projeto üëÅÔ∏è

## 8.1 Cont√™ineres Docker

![C√¥nteires Docker](/assets/images/docker.png)

## 8.2 Banco de Dados Transacional no MySQL

### 8.2.1 Tabelas do Banco de Dados

![Banco de Dados MySQL](/assets/images/mysql_1.png)

### 8.2.2 Tabela de Produtos

![Tabela de Produtos no MySQL](/assets/images/mysql_2.png)

### 8.2.3 Tabela de Pedidos

![Tabela de Pedidos no MySQL](/assets/images/mysql_3.png)

### 8.2.4 Tabela de Endere√ßos

![Tabela de Endere√ßos no MySQL](/assets/images/mysql_4.png)

## 8.3 Airbyte

### 8.3.1 Airbyte Source (Fonte de Dados)

![Source do Airbyte](/assets/images/airbyte_1.png)

### 8.3.2 Airbyte Destination (Destino dos Dados)

![Destination do Airbyte](/assets/images/airbyte_2.png)

### 8.3.3 Airbyte Connections (Conex√£o dos Dados)

![Connection do Airbyte](/assets/images/airbyte_3.png)

![Connection do Airbyte](/assets/images/airbyte_4.png)

## 8.4 √Årea Intermedi√°ria e Banco de Dados Anal√≠tico no PostgreSQL

### 8.4.1 Servidores PostgreSQL

![Servidores PostgreSQL](/assets/images/postgresql_1.png)

### 8.4.2 Servidor da Staging Area

![Servidor da Staging Area](/assets/images/postgresql_2.png)

### 8.4.3 Tabelas no Schema da Staging Area

![Tabelas no Schema da Staging Area](/assets/images/postgresql_3.png)

### 8.4.4 Servidor do Data Warehouse (DW)

![Servidor do Data Warehouse](/assets/images/postgresql_4.png)

### 8.4.5 Tabelas no Schema do Data Warehouse

![Tabelas no Schema do Data Warehouse](/assets/images/postgresql_5.png)

### 8.4.6 Tabela Fato Vendas

![Tabela Fato Vendas](/assets/images/postgresql_6.png)

### 8.4.7 Tabela Dimens√£o Cliente

![Tabela Dimens√£o Cliente](/assets/images/postgresql_7.png)

## 8.5 Airflow

### 8.5.1 √Årea de DAGS

![√Årea de DAGS no Airflow](/assets/images/airflow_1.png)

### 8.5.2 Fluxo da DAG

![Fluxo da DAG no Airflow](/assets/images/airflow_2.png)

![Fluxo da DAG no Airflow](/assets/images/airflow_3.png)

![Fluxo da DAG no Airflow](/assets/images/airflow_4.png)

![Fluxo da DAG no Airflow](/assets/images/airflow_5.png)

![Fluxo da DAG no Airflow](/assets/images/airflow_6.png)

# 9. Instala√ß√£o e Configura√ß√£o üîó

- Pr√©-requisitos:

  1. Baixar e instalar o Docker Desktop;

     Link para download: https://www.docker.com/

  2. Baixar e instalar o PgAdmin (Client do PostgreSQL);

     Link para download: https://www.pgadmin.org/download/

  3. Baixar e instalar o Workbench (Client do MySQL);

     Link para download: https://dev.mysql.com/downloads/workbench/

  4. Baixar e instalar o Airbyte;

     Link para download: https://docs.airbyte.com/using-airbyte/getting-started/oss-quickstart

  5. Baixar e instalar o Git;

     Link para download: https://git-scm.com/downloads

<br>

- Passo a passo:

1. Primeira coisa que precisamos fazer √© instalar o python. Para isso, vamos utilizar o Pyenv que √© um pacote que permite gerenciar diversas vers√µes do Python na mesma m√°quina.

```bash
git clone https://github.com/pyenv-win/pyenv-win.git %USERPROFILE%\.pyenv
```

2. Ap√≥s executar o comando acima, ser√° criada uma pasta no seu usu√°rio chamada .pyenv, que conter√° todos os arquivos necess√°rios para que o Pyenv possa funcionar. Agora, precisamos configurar vari√°veis de ambiente para que o sistema operacional consiga compreender os comandos do Pyenv no prompt de comando. V√° at√© a lupa de pesquisa e procure por "configura√ß√µes avan√ßadas do sistema". Em seguida, clique em "Vari√°veis de ambiente" e posteriormente clique em "Novo" na parte de vari√°veis do usu√°rio. Ap√≥s isso, abrir√° uma janela para incluir o nome e o valor da vari√°vel de ambiente que est√° logo abaixo.

```bash
PYENV=C:\Users\seu_usuario\.pyenv\pyenv-win\
PYENV_HOME=C:\Users\seu_usuario\.pyenv\pyenv-win\
PYENV_ROOT=C:\Users\seu_usuario\.pyenv\pyenv-win\
```

3. Para ter certeza que o Pyenv est√° instalado e funcionando corretamente, abra o prompt de comando e digite:

```bash
pyenv --version
```

4. Se ap√≥s a execu√ß√£o do c√≥digo acima retornar a vers√£o do Pyenv √© porque o sistema operacional j√° est√° conseguindo compreender os comandos. Caso contr√°rio, revise o passo a passo descrito e se for necess√°rio busque ajuda no Google. Por conseguinte, agora com as configura√ß√µes necess√°rias, precisamos instalar o Python atrav√©s do Pyenv.

```bash
pyenv install 3.12.1
```

5. Com o Python instalado, precisamos agora clonar o projeto. Caso queira manter o projeto em uma pasta espec√≠fica, voc√™ pode navegar atrav√©s da estrutura de pastas do seu notebook/computador com o comando "cd nome_pasta". Se n√£o especificar a pasta, provavelmente o projeto ser√° criado na sua pasta de usu√°rio.Feito isso, digite:

```bash
git clone https://github.com/Kjonnathas/DataWarehouse_MySQL_Airflow.git
```

6. Com o projeto clonado, precisamos especificar a vers√£o do python que ir√° rodar no projeto. Para isso, execute o seguinte comando dentro da pasta do projeto:

```bash
pyenv local 3.12.1
```

7. Em seguida, vamos criar nosso ambiente virtual. O ambiente virtual √© uma boa pr√°tica que visa manter um ambiente √∫nico para cada projeto desenvolvido. Sendo assim, execute o comando:

```bash
python -m venv .venv
```

8. Agora precisamos ativar o ambiente virtual. Para isso, execute:

```bash
Set-ExecutionPolicy RemoteSigned -Scope CurrentUser

.venv/Scripts/Activate.ps1
```

9. Depois de ter feito o passo anterior, √© preciso agora realizar a instala√ß√£o das bibliotecas que s√£o utilizadas no projeto. Portanto, dentro da pasta "DataWarehouse_MySQL_Airflow", use o seguinte comando:

```bash
pip install -r requirements.txt
```

10. Nesse momento, podemos come√ßar a cria√ß√£o do cont√©iner que rodar√° o servidor do nosso banco de dados transacional via Docker. Abra o Docker Desktop. Em seguida, abra o prompt de comando caso ainda n√£o esteja aberto ou tenha fechado e execute:

```bash
docker pull mysql:8.0-debian
```

11. O passo acima far√° o download da imagem do MySQL do Docker Hub. Agora, com o download feito, podemos criar o cont√©iner. Depois de executar o comando abaixo, abra o Docker Desktop e veja se o cont√©iner foi criado.

```bash
docker run --name mysql_prod -p 3307:3306 -e MYSQL_ROOT_PASSWORD=escolha_uma_senha -d mysql:8.0-debian
```

12. Vamos aproveitar e criar logo tamb√©m o servidor que usaremos para armazenar a nossa staging area. Ap√≥s executar, fa√ßa o mesmo check no Docker Desktop para averiguar se o cont√©iner foi criado direitinho.

```bash
docker run --name postgres_stg --network bridge -p 5433:5432 -e POSTGRES_DB=escolha_nome_do_banco -e POSTGRES_USER=escolha_nome_do_usuario -e POSTGRES_PASSWORD=escolha_uma_senha -d postgres
```

13. Com o servidor do banco de dados transacional e da staging area criada, podemos avan√ßar na cria√ß√£o das tabelas no banco de dados transacional. Por√©m, antes de criar as tabelas, precisamos configurar o servidor. Para isso, abra o Workbench (Client do MySQL). Ap√≥s abrir, clique no bot√£o de "+" ao lado de "MySQL Connections". Com isso, abrir√° uma janela para inserir as configura√ß√µes. Insira um nome para a conex√£o (da sua escolha), o host - para descobrir o host voc√™ pode executar o seguinte comando no prompt de comando "docker inspect mysql_prod". Ir√° abrir uma estrutura de json e v√° at√© o final e procure por "IPAddress". O valor desse campo √© o host da m√°quina -, a porta (3307) e a senha. Depois disso teste a conex√£o e veja se deu certo. Se der certo, basta clicar sobre a conex√£o que ir√° direcion√°-lo para a tela principal do client.

14. Depois de ter feito o passo anterior, v√° at√© o arquivo "database_transacional.sql" que est√° dentro da pasta "models" que est√° dentro da pasta "src" e copie todo o conte√∫do. Copiado o conte√∫do, volte ao Workbench e cole. Depois selecione todo o conte√∫do colado e execute (CTRL + Enter ou clique no bot√£o de run). Em seguida, fa√ßa um refresh e veja se o banco de dados e as tabelas foram criadas normalmente.

15. Agora que temos o banco de dados e as tabelas criadas, vamos precisar executar um script Python para popular as tabelas que estar√£o simulando nosso ambiente transacional. Procure pelo script "job_etl.py" dentro da pasta "jobs" que est√° dentro da pasta "src". Navegue at√© esta pasta atrav√©s do seu terminal. Voc√™ pode fazer isso usando o seguinte comando:

```bash
cd src/jobs
```

16. Antes de executarmos o script Python, precisamos criar um arquivo ".env" para armazenar algumas vari√°veis de ambiente. Sem elas, o script resultar√° em erro. Portanto, crie este arquivo dentro da pasta "DataWarehouse_MySQL_Airflow" e insira as seguintes informa√ß√µes:

    - MYSQL_USER=root
    - MYSQL_PASSWORD=sua_senha
    - MYSQL_DB=seu_banco_de_dados
    - MYSQL_HOST=seu_host
    - MYSQL_PORT=3307
    - FOLDER_PATH=insira_o_caminho_completo_da_pasta_data
    - FOLDER_LOGS=insira_o_caminho_completo_da_pasta_logs

17. Depois de ter entrado na pasta jobs e configurado o arquivo ".env", basta apenas executar o c√≥digo Python para que ele possa ler os arquivos csv e depois carreg√°-los no banco de dados. Para isso, digite no seu terminal:

```bash
python job_etl.py
```

Fluxo do script "job_etl.py"

```mermaid
graph TD
A[In√≠cio] --> B[Carregar vari√°veis de ambiente com dotenv]
B --> C[Configurar logging]
C --> D[Fun√ß√£o normalize_text]
D --> E[Fun√ß√£o read_files]
E --> F[Fun√ß√£o connection_database]
F --> G[Fun√ß√£o create_table_and_insert_data]
G --> H[Executar script principal]
H --> I[Estabelecer conex√£o com o banco de dados]
I --> J{Conex√£o bem-sucedida?}
J -- Sim --> K[Cria√ß√£o de tabelas e inser√ß√£o de dados]
J -- N√£o --> L[Registrar erro no log]
K --> M{Existem arquivos CSV na pasta?}
M -- Sim --> N[Processar cada arquivo]
N --> O[Normalizar e formatar dados]
O --> P[Inserir dados no banco]
M -- N√£o --> Q[Registrar aviso no log]
P --> R[Commit na transa√ß√£o]
R --> S[Fim]
Q --> S
L --> S
```

18. No banco de dados da staging, a √∫nica coisa que precisa ser feita neste momento √© a cria√ß√£o do schema. Mas antes de criar o schema, precisamos registrar o servidor. Sendo assim, clique em "Servers" com o bot√£o direito e em seguida em "Register" e "Server...". Forne√ßa um nome para o seu servidor da staging area. Ap√≥s isso, v√° at√© a aba de "Connection" e configure o "Host name/address" com o endere√ßo IP da m√°quina ou tente com o nome do cont√©iner, inclua a porta (5433), em "Maintenance database" coloque o nome do banco de dados e, por fim, insira o nome de usu√°rio no campo "Username". Ap√≥s essas configura√ß√µes, clique em save e seu servidor j√° deve estar registrado. Para a cria√ß√£o do schema, voc√™ pode tanto criar manualmente quanto via c√≥digo. Manualmente, bast√° ir at√© o objeto "Schemas" dentro da hierarquia do banco de dados e clicar com o bot√£o direito escolhendo a op√ß√£o "Create" e em seguida "Schema...". Com isso, abrir√° uma janela onde voc√™ incluir√° o nome do Schema na caixa de texto da op√ß√£o "Name" e posteriormente clique em "Save". Com isso, o seu schema ser√° criado. Caso prefira a op√ß√£o via c√≥digo SQL, apenas abra o query tool clicando novamente sobre o objeto Schema e em "Query Tool" e digite "CREATE SCHEMA nome_do_schema" e execute apertando a tecla F5 ou no bot√£o de run e o schema ser√° criado da mesma forma.

19. Se o passo anterior deu certo, podemos avan√ßar na cria√ß√£o do cont√©iner do Airbyte e suas configura√ß√µes. Aqui √© importante que voc√™ j√° tenha feito o download do arquivo que √© disponibilizado pelo Airbyte na pr√≥pria documenta√ß√£o. O arquivo ser√° baixado em uma pasta zipada, portanto, fa√ßa a descompacta√ß√£o da pasta ap√≥s o download ter sido conclu√≠do. Feito isso, precisamos adicionar uma vari√°vel de ambiente para que o sistema operacional reconhe√ßa os comandos do Airbyte. Para isso, v√° at√© suas vari√°veis de ambiente (explicado mais acima como se chega) e procure pela vari√°vel de ambiente "Path" na parte de vari√°veis de ambiente de usu√°rio. Depois que encontrar, clique sobre ela e em seguida em "Editar". Ap√≥s isso, abrir√° uma janela com todas os caminhos associados ao "Path". O que voc√™ precisa fazer √© pegar o caminho completo da pasta do Airbyte e adicionar na √∫ltima linha dispon√≠vel. Depois que o fizer, apenas clique em "Ok" e saia da tela de vari√°veis de ambiente. Caso esteja com o prompt de comando aberto, feche-o e abra novamente.

20. Depois dessas configura√ß√µes, execute o comando abaixo para virmos se o sistema operacional j√° est√° reconhecendo os comandos do Airbyte.

```bash
abctl version
```

21. Caso o prompt de comando retorne a vers√£o do Airbyte significa que est√° tudo certo e podemos prosseguir para a pr√≥xima etapa, que √© cria√ß√£o do cont√©iner do Airbyte. Para isso, precisa estar com o Docker Desktop aberto. Com ele aberto, v√° at√© o seu prompt de comando e digite:

```bash
abctl local install
```

22. Essa etapa costuma demorar pela primeira vez, ent√£o tenha paci√™ncia! √â importante verificar na documenta√ß√£o a exig√™ncia m√≠nima de hardware, pois o Airbyte √© pesado e consome bastante mem√≥ria. Se seu computador n√£o for muito bom, √© prov√°vel que v√° ter problemas com travamento.

23. Ap√≥s a instala√ß√£o ter sido conclu√≠da com sucesso, voc√™ pode abrir seu Docker Desktop e verificar se o cont√©iner do Airbyte foi criado com sucesso. Caso tenha sido, digite o comando abaixo:

```bash
abctl local credentials
```

24. O comando acima lhe dar√° um ID e uma senha, que ser√£o necess√°rios para logar no Airbyte via navegador. Teste a sua conex√£o indo at√© o navegador e acessando "localhost:8000". Insira suas credenciais e o Airbyte lhe levar√° para a tela principal da plataforma.

25. Com o cont√©iner do Airbyte criado precisamos fazer uma configura√ß√£o de rede para que ele consiga se comunicar com os outros cont√©ineres criados anteriormente (do postgresql e do mysql). Se voc√™ retornar na etapa que criamos esses outros dois cont√©neires notar√° que passamos um par√¢metro chamado "--network" e esse par√¢metro √© respons√°vel por dizer em qual rede o cont√©iner estar√° localizado. Portanto, vamos fazer o mesmo agora para o Airbyte. Siga os comandos abaixo em sequ√™ncia. Substituia <rede_atual> pela rede que Airbyte est√° e tamb√©m substitua <container_name> pelo nome do cont√©iner que certamente deve ser "airbyte-abctl-control-plane". O primeiro comando mostrar√° a voc√™ a rede do cont√©iner. O nome da rede est√° antes dos dois pontos e dentro do par de colchetes. Se voc√™ copiar todo o resultado e substituir em <rede_atual> resultar√° em erro. Portanto, pegue exatamente a parte que eu descrevi.

```bash
docker inspect -f '{{.NetworkSettings.Networks}}' <container_name>

docker network disconnect <rede_atual> <container_name>

docker network connect bridge <container_name>
```

26. Com o ambiente do Airbyte agora configurado, precisamos apenas criar a source, o destination e a connection para que a ETL seja capaz de extrair os dados do servidor de produ√ß√£o e lev√°-los ao ambiente da staging area. No painel lateral esquerdo, clique em "Sources". Em seguida, clique em "New source". Na caixa de buscas, procure por "mysql" e clique sobre o conector do MySQL. Agora, aparecer√° uma s√©rie de configura√ß√µes que precisam ser feitas:

    a. Em "Source name" d√™ um nome para a sua fonte de dados;

    b. Em "Host" voc√™ precisa incluir o endere√ßo IP da m√°quina do cont√©iner, usando o comando "docker inspect <container_name>" voc√™ consegue encontrar na parte final da estrutura json que √© retornada. Adicionalmente, voc√™ pode testar se o nome do cont√©iner tamb√©m funciona nessa etapa;

    c. Em "Port" voc√™ precisa colocar a porta mapeada pro cont√©iner. Como a comunica√ß√£o s√£o entre cont√©neires, ou seja, uma comunica√ß√£o apenas no mundo interno, voc√™ ir√° colocar a porta 3306;

    d. Em "Database" precisamos colocar o nome do banco de dados e caso voc√™ n√£o tenha alterado, o nome ser√° "db_prod". N√£o coloque as aspas;

    d. Em "Username" voc√™ vai p√¥r "root". Novamente n√£o inclua as aspas;

    e. Em "Password" inclua a senha que foi definida durante a cria√ß√£o do cont√©iner;

    f. Em "SSL modes" escolha a op√ß√£o "preferred";

    g. Em "Update Method" escolha a op√ß√£o "Scan Changes with User Defined Cursor";

    h. Em "SSH Tunnel Method" escolha a op√ß√£o "No Tunnel".

Feita todas as configura√ß√µes clique em "Test and save". Se o teste concluir sem qualquer erro a source est√° criada.

27. Agora vamos criar e configurar a etapa de Destination. Para isso, clique em "Destinations" no menu lateral esquerdo. Em seguida clique em "New destination". No campo de pesquisa procure por "postgres" e clique no conector. Novamente aparecer√° uma s√©rie de configura√ß√µes que precisam ser realizadas:

    a. Em "Destination name" escolha um nome para o seu destino;

    b. Em "Host" voc√™ seguir√° a mesma explica√ß√£o que foi dada na etapa de configura√ß√£o da Source. Aqui, obviamente, o host ser√° diferente, tanto se voc√™ optar pelo endere√ßo IP quanto atrav√©s do nome do cont√©iner;

    c. Em "Port" voc√™ colocar√° a porta 5432;

    d. Em "DB Name" ter√° que incluir o nome do banco de dados que voc√™ escolheu no momento de criar o cont√©iner do postgresql;

    e. Em "Default Schema" apague o schema public que vem por padr√£o e inclua o schema que foi criado;

    f. Em "User" voc√™ indicar√° o nome do usu√°rio;

    g. Em "SSL modes" escolher√° a op√ß√£o "disable";

    h. Em "SSH Tunnel Method" escolher√° a op√ß√£o "No Tunnel";

    i. Em "Password" voc√™ definir√° a senha escolhida no momento de cria√ß√£o do cont√©iner.

Feita todas as configura√ß√µes clique em "Test and save". Se o teste concluir sem qualquer erro a destination est√° criada.

28. Por fim, vamos criar a nossa connection. Para isso, v√° at√© o menu lateral esquerdo e clique sobre "Connections". Posteriormente clique em "New connection". Nesse momento, o Airbyte apresentar√° as sources que voc√™ tem configurada. Ent√£o, escolha a source que criamos anteriormente. Em seguida, precisamos definir qual ser√° a destination. Similarmente a etapa anterior, basta escolher a destination que criamos e seguir em frente. Com isso, o Airbyte far√° o carregamento e nos dar√° a op√ß√£o de escolher os "streams", que nada mais s√£o do que as tabelas do banco de dados. Selecione todas as tabelas e na parte de "Sync mode" escolha a op√ß√£o "Full refresh | Overwrite + Deduped". Na aba de "Settings" apenas defina o nome da connection e em "schedule type" defina como "Manual". Depois, basta habilitar a connection na parte superior direita e executar o processo clicando em "Sync now".

29. Se a etapa anterior funcionar, vamos seguir em frente para cria√ß√£o do servidor do Data Warehouse, cria√ß√£o das tabelas do DW e ajuste e configura√ß√£o do Airflow para fazer o orquestramento do nosso pipeline de dados.

30. Sendo assim, vamos agora executar o comando que far√° a cria√ß√£o do nosso servidor do DW.

```bash
docker run --name postgres_dw --network bridge -p 5434:5432 -e POSTGRES_DB=db_dw -e POSTGRES_USER=data_warehouse -e POSTGRES_PASSWORD=dw_123 -d postgres
```

31. Logo ap√≥s a execu√ß√£o do passo anterior, fa√ßa aquele check no Docker Desktop para verificar se o cont√©iner foi criado sem problemas.

32. Em seguida n√≥s vamos precisar baixar o arquivo docker compose do Airflow. Normalmente, antes de fazer o download deste arquivo costumamos criar uma pasta na raiz do projeto chamada "airflow", que conter√° al√©m do pr√≥prio arquivo docker compose, alguns outros arquivos e pastas que s√£o necess√°rias para que a ferramenta funcione da maneira adequada. Como inicialmente voc√™ clonou o projeto, essa pasta j√° est√° criada, isto √©, n√£o √© necess√°rio cri√°-la agora. Tendo isso em vista, navegue at√© entrar dentro do diret√≥rio da pasta "airflow". Depois que estiver dentro dela, execute o comando abaixo:

```bash
curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.10.3/docker-compose.yaml'
```

Obs.: O comando curl √© um comando do Linux, portanto, caso voc√™ seu sistema operacional seja Windows, voc√™ tem duas op√ß√µes: Copiar e colar este link no seu navegador e assim que o fizer seu computador/notebook far√° do download do arquivo ou voc√™ pode abrir o terminal do Git que funciona com comandos Linux. Caso queira optar por essa segunda op√ß√£o, v√° at√© seu pesquisador e digite "git bash" e em seguida abra-o. Feito isso, navegue at√© o diret√≥rio da pasta "airflow" e execute o comando acima, que funcionar√° normalmente.

33. Ainda dentro do diret√≥rio do "airflow" precisamos criar algumas pastas que s√£o padr√£o da ferramenta e est√° na documenta√ß√£o. Portanto, fa√ßa o seguinte:

```bash
mkdir -p ./logs ./plugins ./config
echo -e "AIRFLOW_UID=$(id -u)" > .env
```

Obs.: Se por acaso o arquivo ".env" n√£o for criado na pasta, fa√ßa a cria√ß√£o de forma manual, abrindo um editor de texto e incluindo dentro dele "AIRFLOW_UID=50000" e o salve exatamente como ".env".

34. Na sequ√™ncia, vamos executar um comando que far√° a parte de incializa√ß√£o do banco de dados do Airflow.

<strong> Obs.: Antes de prosseguir, v√° at√© a etapa 39 e fa√ßa ela primeiro. Caso voc√™ n√£o fa√ßa a etapa 39 antes de prosseguir, voc√™ ter√° que refazer todas essas etapas novamente, pois ser√° necess√°rio deletar a stack do airflow e cri√°-la novamente para que a configura√ß√£o do arquivo docker-compose seja v√°lida. Ent√£o v√° at√© l√°, fa√ßa a etapa e depois volte aqui para prosseguir. </strong>

```bash
docker compose up airflow-init
```

35. Ap√≥s isso, vamos agora inicializar a stack de cont√©neires do Airflow, executando o seguinte comando:

```bash
docker compose up
```

36. Neste momento √© esperado que a stack de cont√©neires do airflow esteja em pleno funcionamento no Docker Desktop, portanto, v√° at√© l√° e fa√ßa essa verifica√ß√£o. Se preferir voc√™ tamb√©m pode abrir seu terminal - que j√° deve estar aberto - e executar o comando "docker ps" que ir√° listar todos os cont√©ineres em execu√ß√£o.

37. Se tudo estiver corretamente configurado, agora nos falta fazer a configura√ß√£o de rede, pois o Airflow, por padr√£o, cria sua pr√≥pria rede no Docker, chamada de "airflow_default". No entanto, lembre que nossos servidores e nossa plataforma de ETL do Airbyte est√£o na rede "bridge". Para que possamos fazer a comunica√ß√£o entre eles, vamos ter que migrar os cont√©ineres do Airflow para esta outra rede. Sendo assim, execute os seguintes comandos:

```bash
docker network disconnect airflow_default airflow-postgres-1

docker network disconnect airflow_default airflow-redis-1

docker network disconnect airflow_default airflow-airflow-init-1

docker network disconnect airflow_default airflow-airflow-scheduler-1

docker network disconnect airflow_default airflow-airflow-webserver-1

docker network disconnect airflow_default airflow-airflow-worker-1

docker network disconnect airflow_default airflow-airflow-triggerer-1

docker network connect bridge airflow-postgres-1

docker network connect bridge airflow-redis-1

docker network connect bridge airflow-airflow-init-1

docker network connect bridge airflow-airflow-scheduler-1

docker network connect bridge airflow-airflow-webserver-1

docker network connect bridge airflow-airflow-worker-1

docker network connect bridge airflow-airflow-triggerer-1
```

38. A s√©rie de comandos acima far√° a desconex√£o da rede atual e em seguida conectar√° na rede correta. Com isso, a parte de rede est√° corretamente configurada e podemos avan√ßar nas pr√≥ximas configura√ß√µes. Neste momento, vamos entrar dentro do cont√©iner webserver do Airflow para ajustar algumas configura√ß√µes padr√£o. Para isso, vamos precisar instalar o pacote vim do Linux que permitir√° abrir e editar arquivos presentes dentro do cont√©iner. Siga os passos abaixo:

    a. No prompt de comando execute o comando, execute:

    ```bash
    docker exec -it -u root airflow-airflow-webserver-1 bash
    ```

    Por padr√£o o Airflow sempre abre com o usu√°rio default que n√£o possui certos privil√©gios e um deles √© que n√£o pode fazer instala√ß√£o de pacotes. Como precisamos instalar o pacote vim, o comando acima permite a gente entrar no cont√©iner atrav√©s do usu√°rio root que possui esse tipo de privil√©gio.

    b. Agora, execute os comandos na sequ√™ncia:

    ```bash
    apt-get update

    apt-get install vim

    exit
    ```

    c. V√° at√© o Docker Desktop;

    b. Procure pelo cont√©iner airflow-webserver-1 dentro da stack do "airflow";

    c. Clique nos tr√™s pontinhos e depois em "open in terminal";

    d. Assim que o terminal abrir, digite:

    ```bash
    bash
    ```

    e. Em seguida, digite:

    ```bash
    ls -la
    ```

    O comando acima listar√° pastas e arquivos dentro do diret√≥rio corrente, incluindo arquivos e pastas ocultas. Neste momento, voc√™ conseguir√° vir que h√° uma pasta chamada "config". Precisamos entrar dentro dela.

    f. Nesse sentido, vamos prosseguir com o comando abaixo:

    ```bash
    cd config
    ```

    g. Dentro da pasta "config" h√° um arquivo chamado "airflow.cfg". Precisamos abri-lo para manipular o valor de algumas vari√°veis. Dito isto, digite:

    ```bash
    vim airflow.cfg
    ```

    h. Dentro do arquivo "airflow.cfg" tome muito cuidado pois √© um arquivo de configura√ß√£o super importante e que pode danificar o funcionamento do seu Airflow. Fa√ßa exatamente o que est√° sendo dito aqui. Navegue pelo arquivo com o scroll do seu mouse e procure pela vari√°vel "expose_config" e altere seu valor para "True". Para fazer isso, clique na tecla "I" para poder editar o arquivo atrav√©s do vim, ap√≥s ter feito a altera√ß√£o aperte em "ESC" e depois fa√ßa ":w" para salvar a altera√ß√£o. Em seguida, localize a vari√°vel "smtp_host" e altere para "smtp.gmail.com" se seu e-mail for gmail. Caso seja outlook ou algum outro provedor, fa√ßa uma busca no google para descobrir qual √© o smtp dele. Novamente, clique em "I" para poder alterar o arquivo. Em seguida, procure por "smtp_starttls" e coloque como "True". Caso j√° esteja, n√£o precisa alterar, apenas mantenha. Agora, procure por "smtp_ssl" que deve estar logo abaixo e coloque como "False". Se j√° estiver, apenas mantenha. Em "smtp_user" inclua seu e-mail. Em "smtp_password" coloque sua senha. Aqui √© importante estar atento que, n√£o √© poss√≠vel passar sua senha de acesso diretamente. Voc√™ precisa criar uma senha de aplicativo e us√°-la neste caso. V√° at√© o google e procure como cri√°-la. Ap√≥s isso, retorne aqui e inclua esta senha de aplicativo. Em "smtp_port" coloque a porta "587" e em "smtp_mail_from" coloque novamente o seu e-mail. Ap√≥s essas altera√ß√µes, clique em "ESC" e depois fa√ßa ":w" para salvar as altera√ß√µes que foram feitas. Por fim, procure pela vari√°vel "test_connection" e altere de "Disabled" para "Enabled". Essa vari√°vel √© que permite realizar teste de conex√£o na UI (User Interface). Feito isso, fa√ßa ":wq" que ir√° salvar as altera√ß√µes e sair do editor de texto.

39. Para fechar essa etapa √°rdua de configura√ß√£o do Airflow, precisamos fazer dois ajustes no arquivo docker-compose.yaml que est√° presente dentro da pasta "airflow". Abra o arquivo e fa√ßa o seguinte:

    a. Logo abaixo da vari√°vel "AIRFLOW_CONFIG", insira as seguintes vari√°veis:

    - AIRFLOW_SCHEDULER_MIN_FILE_PROCESS_INTERVAL": 5
    - AIRFLOW_SCHEDULER_DAG_DIR_LIST_INTERVAL: 20
    - AIRFLOW_EMAIL_EMAIL_BACKEND: airflow.utils.email.send_email_smtp
    - AIRFLOW_SMTP_SMTP_HOST: "o smtp do seu provedor"
    - AIRFLOW_SMTP_SMTP_STARTTLS: true
    - AIRFLOW_SMTP_SMTP_SSL: false
    - AIRFLOW_SMTP_SMTP_USER: "seu e-mail"
    - AIRFLOW_SMTP_SMTP_MAIL_FROM: "seu e-mail"
    - AIRFLOW_SMTP_SMTP_PASSWORD: "sua senha de aplicativo"
    - AIRFLOW_SMTP_SMTP_PORT: "a porta de conex√£o"

    b. Por fim, dentro da tag "volumes", inclua a seguinte linha:

    - ${AIRFLOW_PROJ_DIR:-.}/models:/opt/airflow/models

Obs.: Ap√≥s a palavra "AIRFLOW", "SCHEDULER" e o primeiro "SMTP" coloque dois underlines em vez de um como est√° especificado. Tentei colocar os dois underlines mas por algum motivo o arquivo n√£o est√° permitindo, portanto, mantive apenas um. Mas se n√£o fizer como estou informando, resultar√° em erro, ent√£o preste bastante aten√ß√£o nisso.

Obs.¬≤: Essa etapa √© necess√°ria para que o Airflow consiga enviar e-mails para voc√™. Sem isso, o seu fluxo ir√° quebrar quando chegar na task que envia o e-mail de sucesso do fluxo.

40. Agora que temos o Airflow com suas configura√ß√µes de rede e configura√ß√µes de parametriza√ß√£o realizadas, vamos criar as tabelas do nosso DW (Data Warehouse). Para isso, abra o PgAdmin (Client do PostgreSQL) e registre o servidor do DW (mostrei na etapa 18 como registrar). Depois que concluir o registro do servidor, v√° at√© o script "database_dw.sql", copie o c√≥digo SQL, v√° at√© seu servidor do DW, abra um query tool, cole o c√≥digo e execute-o. Depois de faz√™-lo, veja se o banco de dados, o schema e as tabelas foram criadas corretamente.

41.

# 10. Licen√ßa

Este projeto est√° licenciado sob os termos da licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
